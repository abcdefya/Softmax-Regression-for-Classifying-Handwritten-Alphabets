{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "90884657-3c7d-4d4b-849d-ddffbbd31e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse \n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "49039ca5-b3c1-422a-917c-36c21bd9cd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 15000 # Rows\n",
    "d = 16 # Features\n",
    "C = 26 # Class numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "504abcdf-8bcd-42f0-99ee-f9a0ea9c161e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_path):\n",
    "    X, Y = [], []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            data = line.strip().split(' ')\n",
    "            label = int(data[0])  # Nhãn là số đầu tiên trong mỗi dòng\n",
    "            features = [float(feature.split(':')[1]) for feature in data[1:]]  # Các đặc trưng từ 1 đến 16\n",
    "            X.append(features)\n",
    "            Y.append(label)\n",
    "    return np.array(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "55974966-f310-4dc8-8345-327e0450de3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 10500)\n",
      "(10500,)\n",
      "(16, 5000)\n",
      "(5000,)\n",
      "(16, 4500)\n",
      "(4500,)\n"
     ]
    }
   ],
   "source": [
    "file_train_path = \"./letter.scale.tr\"\n",
    "file_test_path = \"./letter.scale.t\"\n",
    "file_val_path = \"./letter.scale.val\"\n",
    "\n",
    "# Training dataset\n",
    "X_train, y_train = read_data(file_train_path)\n",
    "X_train = X_train.T\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "# Testing dataset\n",
    "X_test, y_test = read_data(file_test_path)\n",
    "X_test = X_test.T\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "# Validation dataset\n",
    "X_val, y_val= read_data(file_val_path)\n",
    "X_val = X_val.T\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "53d52b75-65d1-4931-9ca9-39b7b878791a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trừ đi 1 bởi vì trong dữ liệu label bắt đầu từ 1 -> 26: \n",
    "# Sau khi trừ 1 thì đảm bảo label từ 0 -> 25\n",
    "y_train = y_train - 1\n",
    "y_test = y_test - 1\n",
    "y_val = y_val - 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d7b35b82-2812-4818-b855-84963d4dfe38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_labels(y, C=C):\n",
    "    \"\"\"\n",
    "    Chuyển đổi mảng nhãn thành dạng ma trận one-hot encoding.\n",
    "\n",
    "    Parameters:\n",
    "        y (array): Mảng chứa các nhãn.\n",
    "        C (int): Số lớp (số cột) trong ma trận one-hot encoding. Mặc định là số lớp C được định nghĩa trước đó.\n",
    "\n",
    "    Returns:\n",
    "        array: Ma trận one-hot encoding của các nhãn.\n",
    "    \"\"\"\n",
    "    Y = sparse.coo_matrix((np.ones_like(y), \n",
    "        (y, np.arange(len(y)))), shape=(C, len(y))).toarray()\n",
    "    return Y \n",
    "\n",
    "\n",
    "def loss(X, Y_hat, theta):\n",
    "    Y = softmax_stable(np.dot(theta.T, X))\n",
    "    eps = 1e-15\n",
    "    Y_hat = np.clip(Y_hat, eps, 1 - eps)\n",
    "\n",
    "    # Tính toán cross entropy loss\n",
    "    loss = -np.sum(Y * np.log(Y_hat)) / Y.shape[1]\n",
    "    return loss\n",
    "\n",
    "def softmax(Z):\n",
    "    \"\"\"\n",
    "    Tính hàm softmax cho ma trận đầu vào Z.\n",
    "\n",
    "    Parameters:\n",
    "        Z (array): Ma trận đầu vào.\n",
    "\n",
    "    Returns:\n",
    "        array: Ma trận chứa kết quả của hàm softmax.\n",
    "    \"\"\"\n",
    "    e_Z = np.exp(Z)\n",
    "    A = e_Z / e_Z.sum(axis=0)\n",
    "    return A\n",
    "\n",
    "def softmax_stable(Z):\n",
    "    \"\"\"\n",
    "    Tính hàm softmax ổn định cho ma trận đầu vào Z.\n",
    "\n",
    "    Parameters:\n",
    "        Z (array): Ma trận đầu vào.\n",
    "\n",
    "    Returns:\n",
    "        array: Ma trận chứa kết quả của hàm softmax ổn định.\n",
    "    \"\"\"\n",
    "    e_Z = np.exp(Z - np.max(Z, axis=0, keepdims=True))\n",
    "    A = e_Z / e_Z.sum(axis=0)\n",
    "    return A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ca3ae7b7-fe87-40d7-b9c7-b4533b888f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_score(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Tính độ chính xác của dự đoán.\n",
    "    \n",
    "    Parameters:\n",
    "        y_true (array): Nhãn thực sự.\n",
    "        y_pred (array): Nhãn dự đoán.\n",
    "    \n",
    "    Returns:\n",
    "        float: Độ chính xác của dự đoán, được tính dưới dạng phần trăm.\n",
    "    \"\"\"\n",
    "    correct_predictions = np.sum(y_true == y_pred)\n",
    "    total_predictions = len(y_true)\n",
    "    accuracy = (correct_predictions / total_predictions) * 100\n",
    "    return accuracy\n",
    "\n",
    "def predict(theta, X):\n",
    "    \"\"\"\n",
    "    Dự đoán nhãn của các mẫu đầu vào bằng mô hình softmax.\n",
    "    \n",
    "    Parameters:\n",
    "        theta (array): Ma trận trọng số.\n",
    "        X (array): Ma trận các mẫu đầu vào.\n",
    "    \n",
    "    Returns:\n",
    "        array: Nhãn dự đoán cho các mẫu đầu vào.\n",
    "    \"\"\"\n",
    "    A = softmax_stable(np.dot(theta.T, X))\n",
    "    return np.argmax(A, axis=0)\n",
    "\n",
    "\n",
    "def calculate_f1_score(y_true, y_pred):\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    return precision, recall, f1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a414d68d-fafc-493a-a045-0d9f8b780495",
   "metadata": {},
   "source": [
    "#### Hàm với cỡ bước hằng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "905797dc-13ac-46c5-893e-980de7c7cc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_regression(X, y, theta_init, eta, tol=1e-8, max_count=500000):\n",
    "    theta = theta_init\n",
    "    C = theta.shape[1]\n",
    "    Y = convert_labels(y, C)\n",
    "    N = X.shape[1]\n",
    "    d = X.shape[0]\n",
    "    \n",
    "    count = 0\n",
    "    prev_theta = theta\n",
    "\n",
    "    while count < max_count:\n",
    "        # Shuffle data\n",
    "        mix_id = np.random.permutation(N)\n",
    "        for i in mix_id:\n",
    "            xi = X[:, i].reshape(d, 1)\n",
    "            yi = Y[:, i].reshape(C, 1)\n",
    "            ai = softmax(np.dot(theta.T, xi))\n",
    "            grad = xi.dot((ai - yi).T)\n",
    "            theta_new = theta - eta * grad\n",
    "            count += 1\n",
    "            \n",
    "            # Check for convergence\n",
    "            if np.linalg.norm(theta_new - prev_theta) < tol:\n",
    "                return theta_new\n",
    "            \n",
    "            prev_theta = theta\n",
    "            theta = theta_new\n",
    "    \n",
    "    return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b557b69e-29f4-409c-8f9c-8a1ec8e22fab",
   "metadata": {},
   "source": [
    "#### Backtracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaaae2dd-95bd-4e9e-a934-28009a9b79b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtraking_softmax(X_train, y_train, eta=1, m=0.5, alpha=0.5, batch_size=1024, epochs=256):\n",
    "    y_train1hot = covert_labels(y_train, 26)\n",
    "    d, C = X_train.shape[0], y_train1hot.shape[0]\n",
    "    theta_init = np.random.randn(d, C)\n",
    "    theta = [theta_init]\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for i in range(0, X_train.shape[1], batch_size):\n",
    "            # Get the batch\n",
    "            X_batch = X_train[:, i:i+batch_size]\n",
    "            y_batch = y_train1hot[:, i:i+batch_size]\n",
    "\n",
    "            # Compute the gradient over the batch\n",
    "            ai = softmax_stable(np.dot(theta[-1].T, X_batch))\n",
    "            grad = np.dot(X_batch, (ai - y_batch).T) / batch_size\n",
    "\n",
    "            # Update theta with backtracking line search\n",
    "            theta_new = theta[-1] - eta * grad\n",
    "            t_k = eta\n",
    "            j = 0\n",
    "            while (loss(X_train, y_train1hot, theta_new) > loss(X_train, y_train1hot, theta[-1]) - m * t_k * np.linalg.norm(grad) ** 2) and (j < 5):\n",
    "                t_k *= alpha\n",
    "                theta_new = theta[-1] - t_k * grad\n",
    "                j += 1\n",
    "\n",
    "            # Append the new theta to the list\n",
    "            theta.append(theta_new)\n",
    "            if np.linalg.norm(theta[-1] - theta[-2]) < 1e-8:\n",
    "                print(f\"Converged at epoch {epoch + 1}, iteration {i // batch_size + 1}\")\n",
    "                return theta[-1]\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}, Loss: {loss(X_train, y_train1hot, theta[-1])}\")\n",
    "\n",
    "    # Final trained theta\n",
    "    return theta[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afffa8f8-4cc8-4994-a91e-f0df37e57aa0",
   "metadata": {},
   "source": [
    "# Khởi tạo mô hình và thực hiện huấn luyện mô hình"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11255377-9ff4-437e-bec4-b27870768526",
   "metadata": {},
   "source": [
    "## Cỡ bước hằng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c8d8ae81-c661-4cee-84bf-ac36872170c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eta = 0.03\n",
    "theta_init = np.random.randn(d, C)\n",
    "theta = softmax_regression(X_train, y_train, theta_init, eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b3b4f904-4578-4863-b865-68b08dce2226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.88501781e+00 -3.88669282e+00  1.95927367e+00 -6.70307773e+00\n",
      "  -3.46994370e+00 -2.19348469e+00  5.59219282e-01 -3.72411275e+00\n",
      "   4.06262205e+00  8.00802768e-01  3.07447379e-01  8.94228769e-01\n",
      "   2.01929006e+00 -8.84638022e-01 -1.79335821e+00  1.55769810e+00\n",
      "   3.36229571e+00 -1.66386626e+00 -7.30402301e-03  2.75639627e+00\n",
      "   4.27822064e-01  2.08203623e+00  4.42576480e+00 -4.22983615e-01\n",
      "   4.13621221e+00 -9.58070985e-01]\n",
      " [-2.98590036e+00  2.36207593e+00  1.32532341e+00  4.97967988e+00\n",
      "   1.19852941e+00 -9.56621221e-01  5.68393998e-01  8.79163368e-01\n",
      "  -7.05822995e-01 -3.59418940e+00 -1.36923288e+00  4.72436712e-01\n",
      "  -6.18988838e-01 -2.09659537e-01  1.80075249e+00 -3.25452999e+00\n",
      "  -2.59780429e+00  7.87164870e-01 -8.98249251e-01  1.26065400e+00\n",
      "   2.16140259e+00  5.07993595e-01 -2.30362522e+00 -1.34374182e+00\n",
      "  -2.65773813e+00 -4.24161220e+00]\n",
      " [ 3.08431212e+00 -1.54204028e+00 -2.19266037e+00 -1.58592464e+00\n",
      "  -2.93003322e+00  3.13419090e-01  2.54440724e+00  9.91270381e+00\n",
      "  -1.08180425e+01 -3.53719092e+00  5.46113454e+00 -3.24205444e+00\n",
      "   7.46493071e+00  6.94681574e+00  2.67090606e+00  2.85412707e-01\n",
      "  -1.28126404e+00  2.71406137e-01  2.20658199e+00 -5.02944577e+00\n",
      "  -5.87424254e-01  1.78578971e+00  1.85153134e+00  6.14079751e+00\n",
      "  -5.64737371e-01 -3.51477358e+00]\n",
      " [ 4.77072755e+00 -5.22651085e+00 -1.94592267e+00 -6.90701919e+00\n",
      "  -2.20178083e+00  1.19305395e+00 -1.60221175e+00 -5.36951720e+00\n",
      "   5.93847169e+00  8.48313231e+00  1.59382477e-01  1.25575165e+00\n",
      "  -6.58991759e+00 -1.35696202e+00 -1.46373181e+00  2.65596202e+00\n",
      "   5.44421958e+00 -2.37532741e+00  1.61727069e+00 -1.00902614e+00\n",
      "  -3.88842859e+00 -7.82990639e-01 -2.01628412e+00  4.12235835e+00\n",
      "   3.12267232e+00  4.67880856e+00]\n",
      " [-3.15230307e+00  4.48181640e+00 -9.85488630e-01  5.25746846e+00\n",
      "   3.93082003e+00  2.40583893e+00 -1.35259557e+00  1.16822825e+00\n",
      "   1.84971181e+00 -1.85120313e+00 -4.26734623e+00  2.09796684e+00\n",
      "  -4.45287562e-01 -2.30697020e+00 -1.57345864e+00  2.83334075e+00\n",
      "  -2.51763367e+00  1.60618036e+00 -3.87759699e+00  3.55566633e+00\n",
      "   2.80360821e+00 -1.14576737e+00  9.24654048e-01 -1.11448900e+01\n",
      "  -1.82843800e+00  1.05427667e+00]\n",
      " [ 4.95682884e+00 -2.08406452e+00 -1.80836751e+00 -6.17313231e-01\n",
      "  -2.68444575e+00 -2.92168141e+00 -1.71048350e+00  1.91410006e-01\n",
      "   3.19346873e+00  1.00432460e+01 -8.67865380e+00 -3.53636814e+00\n",
      "   8.41542137e-01 -2.83653905e+00  3.97757695e-01 -1.56127826e+00\n",
      "   6.08908940e+00 -2.96917227e+00  2.54982344e+00  3.78750991e+00\n",
      "  -1.66481936e+00 -2.08257271e+00 -2.39210193e+00  1.95891438e-01\n",
      "   1.59708880e+00  5.97109189e+00]\n",
      " [-3.36618206e+00 -2.31653091e+00  3.33588009e+00 -5.10048216e+00\n",
      "   3.20425090e+00  4.90475125e+00 -4.08841588e+00  2.52900548e+00\n",
      "  -3.25748022e+00  1.62959277e+00  4.57484957e-02 -1.22102403e+01\n",
      "   3.10716429e-01  3.97921601e+00  3.90775927e-02 -1.91756166e-01\n",
      "  -4.38764872e+00  6.63145835e+00 -3.66269039e+00  1.16001292e+01\n",
      "  -5.02205906e+00  9.66931497e-01  1.30811922e+00 -1.98383484e+00\n",
      "  -2.70375967e+00 -2.48598866e+00]\n",
      " [-7.94641069e-01  7.55934256e-01  1.02284228e+00  5.05527239e+00\n",
      "  -2.66909799e+00 -2.40859767e+00  2.14486771e+00  5.10219689e+00\n",
      "  -4.46201375e+00 -1.39089356e-01 -4.50679650e+00 -2.84126169e+00\n",
      "   3.41931953e+00  4.00196868e+00  5.33241954e+00  2.89708209e+00\n",
      "   1.84354063e+00  7.77816392e-01 -5.53714322e-01 -2.21448279e+00\n",
      "   2.87900141e+00  2.11825000e-01  7.10025586e-01 -8.98768526e+00\n",
      "  -2.44468358e+00 -2.90709631e+00]\n",
      " [-5.53594711e+00  1.12461214e+00  3.34250050e+00  4.97794889e+00\n",
      "   6.40030494e+00 -1.33862753e+00 -1.22373150e+00 -4.13291832e+00\n",
      "   3.19937574e+00 -5.93390372e-01  4.97351816e-01  4.58904125e+00\n",
      "  -3.34923410e+00 -2.98046555e+00 -2.52559853e+00 -6.90117590e+00\n",
      "  -4.58867505e+00 -1.58056977e+00  1.37548442e+00  7.83644692e+00\n",
      "   3.04735246e+00 -7.23954786e+00 -6.72805827e+00  3.12556643e+00\n",
      "  -1.87758012e+00  9.08696317e+00]\n",
      " [-2.89806666e+00  2.86909137e+00  1.03728313e+00  5.35583721e+00\n",
      "   5.16672771e+00  5.80303456e+00 -1.47657623e+00  1.66124624e+00\n",
      "   1.22784010e+00  6.03543238e+00 -5.77795968e-01 -3.11186032e+00\n",
      "  -1.97331771e+00 -4.94842706e-01  1.00564475e+00  4.72174038e+00\n",
      "  -3.54502703e+00 -6.85383812e-01  2.87126006e+00 -9.97435931e-01\n",
      "  -5.55962686e+00 -3.83321433e+00 -2.79612928e+00 -4.23423283e+00\n",
      "  -3.04838974e+00  7.61408169e+00]\n",
      " [-3.50687179e+00 -2.52451174e+00  9.94570108e-01 -4.42396459e+00\n",
      "  -1.51180497e+00  8.45319777e-02 -6.38182259e-01 -3.36262272e+00\n",
      "   3.45902280e+00  2.26016034e+00 -2.96502118e+00 -3.26417127e-01\n",
      "  -1.80554902e+00 -4.81512898e+00 -3.85933525e+00 -8.69776500e-01\n",
      "  -1.28778573e-03 -8.66911894e+00  1.39133776e-01 -1.07714078e+00\n",
      "   6.02207282e+00  9.40653430e+00  5.05217749e+00  1.88871086e+00\n",
      "   1.20605801e+01 -1.51704802e+00]\n",
      " [ 3.13733396e+00 -8.23831872e+00  1.34321320e+01 -1.07332489e+01\n",
      "   8.47631567e+00 -5.16133092e+00  6.63951282e+00  9.89394670e-01\n",
      "  -2.87964516e+00 -5.41180289e-01  6.94566793e+00  4.01352430e+00\n",
      "   4.52187612e+00 -1.34508999e+00  1.94401148e+00 -1.21809125e+01\n",
      "   4.80629999e+00 -1.29621043e+00 -7.70453073e-01  6.46168382e-02\n",
      "   3.61934992e+00 -5.44803328e+00 -3.18326515e+00 -5.64864254e-01\n",
      "  -4.64509082e+00  1.65216474e+00]\n",
      " [ 1.47051817e+00 -4.07341689e+00  1.50609646e+00 -8.06062636e-02\n",
      "  -2.84967840e+00 -1.62991160e+00 -3.88652833e+00  1.04353184e+00\n",
      "  -5.10674305e+00 -5.11032906e+00  3.97758051e+00 -2.08640066e+00\n",
      "   1.54446173e+01  8.56546181e+00 -8.43804317e-01 -1.92076501e+00\n",
      "  -4.94703941e+00  4.03117482e-01 -8.63193564e+00 -3.44809976e+00\n",
      "   4.60188483e+00  3.44723109e+00  1.26815214e+01  1.09050183e+00\n",
      "  -4.66998297e+00 -7.17350010e+00]\n",
      " [-4.78274064e+00 -2.54526931e-01  4.31647221e+00 -2.34440028e+00\n",
      "   7.75536473e-01  1.90499797e+00  3.58765456e+00 -2.65177793e-02\n",
      "  -1.52809344e+00 -6.99166904e+00 -2.68192326e+00  8.20520054e-01\n",
      "  -8.32158716e+00 -1.23518037e+00  2.38742433e+00  5.52441975e+00\n",
      "   2.50370974e+00 -5.98132613e+00 -1.48583079e-01  5.15077769e+00\n",
      "   1.00521376e+00  3.54330286e+00  2.08777111e+00 -1.22293895e+00\n",
      "   8.25567681e+00 -6.03898343e-02]\n",
      " [-2.66062531e+00  6.55778198e+00  2.39751309e-01 -5.78507861e-01\n",
      "   7.76290367e+00  2.91800727e+00  2.06948752e+00 -6.64362229e+00\n",
      "   1.96402993e-01  1.86772681e+00 -7.67823444e-01  7.98479954e-01\n",
      "  -1.25898179e+01 -1.15725547e+01 -3.04000564e+00  8.00326561e-01\n",
      "   2.19106661e+00  1.73198795e-01  8.48797544e+00 -6.70162648e-01\n",
      "  -1.18506564e+01 -2.09703728e+00 -1.02071101e+01  4.87789293e+00\n",
      "   4.02858112e+00  1.29220792e+01]\n",
      " [-4.26899271e+00  4.83606032e+00  5.61152871e+00 -2.49948627e+00\n",
      "   5.20268389e+00  1.04092232e+00  4.99968720e+00  4.63840350e-01\n",
      "   4.89201661e-02 -4.86262211e+00  7.79015342e+00  1.30829083e+00\n",
      "  -3.68661730e+00 -4.89375794e+00 -6.70502165e-01  2.40793213e+00\n",
      "   3.22286229e+00  4.76968027e+00 -1.82352218e+00 -4.05235599e+00\n",
      "  -7.36019390e+00  1.10405131e+00 -2.02467916e+00  4.17249114e-01\n",
      "  -4.45316869e+00 -4.56424922e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27357343-4862-4024-be48-a8b12108f790",
   "metadata": {},
   "source": [
    "### Dự đoán mô hình với cỡ bước hằng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0626fc40-e7b0-4481-ad82-5387f321ef2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Các lớp được dự đoán cho tập huấn luyện với 20 dữ liệu đầu:\n",
      " [21 11  8  2 21 10  9  3  7  6  9  4  3  2 21 18 24 11 23 19]\n",
      "Các lớp thực sự cho tập huấn luyện với 20 dữ liệu đầu:\n",
      " [21 11  8  2 21 10  9  3  7  6  9  2  3  6 21  0 24 11 23 19]\n",
      "Độ chính xác cho tập huấn luyện: 75.61%\n",
      "Precision có trọng số trên tập huấn luyện: 0.75\n",
      "Recall có trọng số trên tập huấn luyện: 0.76\n",
      "F1 score có trọng số trên tập huấn luyện: 0.75\n"
     ]
    }
   ],
   "source": [
    "# Dự đoán trên tập huấn luyện\n",
    "Y_train_pred = predict(theta, X_train)  \n",
    "print(\"Các lớp được dự đoán cho tập huấn luyện với 20 dữ liệu đầu:\\n\", Y_train_pred[:20])\n",
    "print(\"Các lớp thực sự cho tập huấn luyện với 20 dữ liệu đầu:\\n\", y_train[:20])\n",
    "acc_train = accuracy_score(y_train.T, Y_train_pred)\n",
    "print(f\"Độ chính xác cho tập huấn luyện: {acc_train:.2f}%\")\n",
    "\n",
    "# Tính Precision, Recall và F1 score trên tập huấn luyện\n",
    "precision, recall, f1 = calculate_f1_score(y_train, Y_train_pred)\n",
    "\n",
    "print(f'Precision có trọng số trên tập huấn luyện: {precision:.2f}')\n",
    "print(f'Recall có trọng số trên tập huấn luyện: {recall:.2f}')\n",
    "print(f'F1 score có trọng số trên tập huấn luyện: {f1:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b058d278-b489-41c7-bcc1-bbc65a5080f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Các lớp được dự đoán cho tập kiểm thử cho 20 dữ liệu đầu:\n",
      " [16 17  5  5 19 19 16  9  2 14 21  8 13 17  4 16  5 23  5  4]\n",
      "Các lớp thực sự cho tập kiểm thử cho 20 dữ liệu đầu:\n",
      " [16 17  5  5 19 19  6 25  2 14 21  8  7  3  4 16 15 23  5  4]\n",
      "Độ chính xác cho tập kiểm thử: 75.08%\n",
      "Precision có trọng số trên tập kiểm thử: 0.75\n",
      "Recall có trọng số trên tập kiểm thử: 0.75\n",
      "F1 có trọng số trên tập kiểm thử: 0.75\n"
     ]
    }
   ],
   "source": [
    "# Dự đoán trên tập kiểm thử\n",
    "Y_test_pred = predict(theta, X_test)\n",
    "print(\"Các lớp được dự đoán cho tập kiểm thử cho 20 dữ liệu đầu:\\n\", Y_test_pred[:20])\n",
    "print(\"Các lớp thực sự cho tập kiểm thử cho 20 dữ liệu đầu:\\n\", y_test[:20])\n",
    "\n",
    "acc_test = accuracy_score(y_test.T, Y_test_pred)\n",
    "print(f\"Độ chính xác cho tập kiểm thử: {acc_test:.2f}%\")\n",
    "\n",
    "\n",
    "# Tính Precision, Recall và F1 score trên tập kiểm thử\n",
    "test_precision, test_recall, test_f1 = calculate_f1_score(y_test, Y_test_pred)\n",
    "\n",
    "print(f'Precision có trọng số trên tập kiểm thử: {test_precision:.2f}')\n",
    "print(f'Recall có trọng số trên tập kiểm thử: {test_recall:.2f}')\n",
    "print(f'F1 có trọng số trên tập kiểm thử: {test_f1:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d06e9b35-7c95-4e0c-bace-d8649a670e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Các lớp được dự đoán cho tập thẩm định cho 20 dữ liệu đầu:\n",
      " [13  5  2 10  9 11  0  1 17  4 25  1 15 11 13 17  5 12  4 19]\n",
      "Các lớp thực sự cho tập thẩm định cho 20 dữ liệu đầu:\n",
      " [13  5  6 17  9 11  0  1 18 25 18  1 15 11 13 17  5 12  4 19]\n",
      "Độ chính xác cho tập thẩm định: 75.22%\n",
      "Precision có trọng số trên tập thẩm định: 0.75\n",
      "Recall có trọng số trên tập thẩm định: 0.75\n",
      "F1 score có trọng số trên tập thẩm định: 0.75\n"
     ]
    }
   ],
   "source": [
    "# Dự đoán trên tập thẩm định\n",
    "Y_val_pred = predict(theta, X_val)\n",
    "print(\"Các lớp được dự đoán cho tập thẩm định cho 20 dữ liệu đầu:\\n\", Y_val_pred[:20])\n",
    "print(\"Các lớp thực sự cho tập thẩm định cho 20 dữ liệu đầu:\\n\", y_val[:20])\n",
    "\n",
    "acc_test = accuracy_score(y_val, Y_val_pred.T)\n",
    "print(f\"Độ chính xác cho tập thẩm định: {acc_test:.2f}%\")\n",
    "\n",
    "# Tính Precision, Recall và F1 score trên tập thẩm định\n",
    "val_precision, val_recall, val_f1 = calculate_f1_score(y_val, Y_val_pred)\n",
    "\n",
    "print(f'Precision có trọng số trên tập thẩm định: {val_precision:.2f}')\n",
    "print(f'Recall có trọng số trên tập thẩm định: {val_recall:.2f}')\n",
    "print(f'F1 score có trọng số trên tập thẩm định: {val_f1:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c106ef6e-78a3-4d32-90f0-151e4757cb9c",
   "metadata": {},
   "source": [
    "## Backtracking (Armijo step size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f88dcc46-835f-4104-bb4f-0d564dcf9b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 33.16045732665291\n",
      "Epoch 2, Loss: 33.144123032225366\n",
      "Epoch 3, Loss: 33.12822025718436\n",
      "Epoch 4, Loss: 33.11267615627507\n",
      "Epoch 5, Loss: 33.09743436884965\n",
      "Epoch 6, Loss: 33.082449184699335\n",
      "Epoch 7, Loss: 33.06768182279427\n",
      "Epoch 8, Loss: 33.053098200097075\n",
      "Epoch 9, Loss: 33.03866764896077\n",
      "Epoch 10, Loss: 33.02436219262147\n",
      "Epoch 11, Loss: 33.01015612717938\n",
      "Epoch 12, Loss: 32.99602576143215\n",
      "Epoch 13, Loss: 32.98194923352935\n",
      "Epoch 14, Loss: 32.96790636397054\n",
      "Epoch 15, Loss: 32.92774640301987\n",
      "Epoch 16, Loss: 32.887892276038535\n",
      "Epoch 17, Loss: 32.80198203646321\n",
      "Epoch 18, Loss: 32.601982446755706\n",
      "Epoch 19, Loss: 32.3031404406124\n",
      "Epoch 20, Loss: 31.965991772614924\n",
      "Epoch 21, Loss: 31.619066700777346\n",
      "Epoch 22, Loss: 31.276407507500423\n",
      "Epoch 23, Loss: 30.94208583139057\n",
      "Epoch 24, Loss: 30.616846543893327\n",
      "Epoch 25, Loss: 30.300852256946992\n",
      "Epoch 26, Loss: 29.994417833632713\n",
      "Epoch 27, Loss: 29.698042233897844\n",
      "Epoch 28, Loss: 29.412221368988334\n",
      "Epoch 29, Loss: 29.13725439922613\n",
      "Epoch 30, Loss: 28.873151173268948\n",
      "Epoch 31, Loss: 28.619649755275308\n",
      "Epoch 32, Loss: 28.376294140837455\n",
      "Epoch 33, Loss: 28.142520954101634\n",
      "Epoch 34, Loss: 27.917728225256422\n",
      "Epoch 35, Loss: 27.701320301852675\n",
      "Epoch 36, Loss: 27.4927329088594\n",
      "Epoch 37, Loss: 27.29144467557189\n",
      "Epoch 38, Loss: 27.096980505485398\n",
      "Epoch 39, Loss: 26.90891050480188\n",
      "Epoch 40, Loss: 26.726846765924883\n",
      "Epoch 41, Loss: 26.550439320025344\n",
      "Epoch 42, Loss: 26.379371960469665\n",
      "Epoch 43, Loss: 26.213358281355685\n",
      "Epoch 44, Loss: 26.052138077000517\n",
      "Epoch 45, Loss: 25.89547414373861\n",
      "Epoch 46, Loss: 25.743149474109785\n",
      "Epoch 47, Loss: 25.59496481124668\n",
      "Epoch 48, Loss: 25.450736524088846\n",
      "Epoch 49, Loss: 25.3102947641683\n",
      "Epoch 50, Loss: 25.173481867924853\n",
      "Epoch 51, Loss: 25.040150972662587\n",
      "Epoch 52, Loss: 24.910164818341364\n",
      "Epoch 53, Loss: 24.78339471101714\n",
      "Epoch 54, Loss: 24.659719626817747\n",
      "Epoch 55, Loss: 24.539025437922277\n",
      "Epoch 56, Loss: 24.421204244200347\n",
      "Epoch 57, Loss: 24.30615379605959\n",
      "Epoch 58, Loss: 24.19377699572303\n",
      "Epoch 59, Loss: 24.083981465666326\n",
      "Epoch 60, Loss: 23.97667917431963\n",
      "Epoch 61, Loss: 23.871786110399142\n",
      "Epoch 62, Loss: 23.769221998384168\n",
      "Epoch 63, Loss: 23.668910048702628\n",
      "Epoch 64, Loss: 23.570776737128973\n",
      "Epoch 65, Loss: 23.474751608738256\n",
      "Epoch 66, Loss: 23.380767102498258\n",
      "Epoch 67, Loss: 23.288758393225628\n",
      "Epoch 68, Loss: 23.198663248186016\n",
      "Epoch 69, Loss: 23.110421896090745\n",
      "Epoch 70, Loss: 23.02397690664125\n",
      "Epoch 71, Loss: 22.939273079106368\n",
      "Epoch 72, Loss: 22.856257338693943\n",
      "Epoch 73, Loss: 22.774878639705825\n",
      "Epoch 74, Loss: 22.695087874651637\n",
      "Epoch 75, Loss: 22.616837788647352\n",
      "Epoch 76, Loss: 22.54008289854662\n",
      "Epoch 77, Loss: 22.464779416350886\n",
      "Epoch 78, Loss: 22.390885176521884\n",
      "Epoch 79, Loss: 22.318359566882915\n",
      "Epoch 80, Loss: 22.247163462844377\n",
      "Epoch 81, Loss: 22.177259164728135\n",
      "Epoch 82, Loss: 22.10970366257455\n",
      "Epoch 83, Loss: 22.047342689085585\n",
      "Epoch 84, Loss: 21.988716542329282\n",
      "Epoch 85, Loss: 21.932484263196308\n",
      "Epoch 86, Loss: 21.877991013442582\n",
      "Epoch 87, Loss: 21.824854552146824\n",
      "Epoch 88, Loss: 21.772840508434424\n",
      "Epoch 89, Loss: 21.721798532806197\n",
      "Epoch 90, Loss: 21.671627879728263\n",
      "Epoch 91, Loss: 21.62225806063587\n",
      "Epoch 92, Loss: 21.573637586317332\n",
      "Epoch 93, Loss: 21.52572722356235\n",
      "Epoch 94, Loss: 21.478495853422178\n",
      "Epoch 95, Loss: 21.431917869798163\n",
      "Epoch 96, Loss: 21.38597151130456\n",
      "Epoch 97, Loss: 21.34063777022133\n",
      "Epoch 98, Loss: 21.295899664974822\n",
      "Epoch 99, Loss: 21.251741745653963\n",
      "Epoch 100, Loss: 21.208149751455036\n",
      "Epoch 101, Loss: 21.165110368834906\n",
      "Epoch 102, Loss: 21.12261105752649\n",
      "Epoch 103, Loss: 21.080639923034955\n",
      "Epoch 104, Loss: 21.0391856214854\n",
      "Epoch 105, Loss: 20.998237287344967\n",
      "Epoch 106, Loss: 20.957784477566925\n",
      "Epoch 107, Loss: 20.917817127698306\n",
      "Epoch 108, Loss: 20.878325516825374\n",
      "Epoch 109, Loss: 20.839300239134467\n",
      "Epoch 110, Loss: 20.800732180486886\n",
      "Epoch 111, Loss: 20.762612498839072\n",
      "Epoch 112, Loss: 20.724932607644778\n",
      "Epoch 113, Loss: 20.687684161594735\n",
      "Epoch 114, Loss: 20.65085904420753\n",
      "Epoch 115, Loss: 20.614449356901122\n",
      "Epoch 116, Loss: 20.578447409260935\n",
      "Epoch 117, Loss: 20.542845710283817\n",
      "Epoch 118, Loss: 20.507636960426424\n",
      "Epoch 119, Loss: 20.472814044322774\n",
      "Epoch 120, Loss: 20.438370024064334\n",
      "Epoch 121, Loss: 20.40429813295758\n",
      "Epoch 122, Loss: 20.370591769691192\n",
      "Epoch 123, Loss: 20.337244492857696\n",
      "Epoch 124, Loss: 20.30425001578533\n",
      "Epoch 125, Loss: 20.271602201643624\n",
      "Epoch 126, Loss: 20.23929505879291\n",
      "Epoch 127, Loss: 20.207322736353003\n",
      "Epoch 128, Loss: 20.175679519970487\n",
      "Epoch 129, Loss: 20.144359827767143\n",
      "Epoch 130, Loss: 20.113358206455125\n",
      "Epoch 131, Loss: 20.08266932760607\n",
      "Epoch 132, Loss: 20.05228798406357\n",
      "Epoch 133, Loss: 20.022209086489653\n",
      "Epoch 134, Loss: 19.99242766003693\n",
      "Epoch 135, Loss: 19.962938841139447\n",
      "Epoch 136, Loss: 19.934104966860097\n",
      "Epoch 137, Loss: 19.9066492751591\n",
      "Epoch 138, Loss: 19.88082340121278\n",
      "Epoch 139, Loss: 19.85690768319401\n",
      "Epoch 140, Loss: 19.834261626762515\n",
      "Epoch 141, Loss: 19.812453355968216\n",
      "Epoch 142, Loss: 19.791225799577802\n",
      "Epoch 143, Loss: 19.7704210577478\n",
      "Epoch 144, Loss: 19.749939719638682\n",
      "Epoch 145, Loss: 19.72971791174514\n",
      "Epoch 146, Loss: 19.709713858133426\n",
      "Epoch 147, Loss: 19.689899775367618\n",
      "Epoch 148, Loss: 19.670256868302047\n",
      "Epoch 149, Loss: 19.65077218163726\n",
      "Epoch 150, Loss: 19.6314365890112\n",
      "Epoch 151, Loss: 19.61224349321767\n",
      "Epoch 152, Loss: 19.59318797817613\n",
      "Epoch 153, Loss: 19.574266251626813\n",
      "Epoch 154, Loss: 19.55547527687087\n",
      "Epoch 155, Loss: 19.536812528443843\n",
      "Epoch 156, Loss: 19.518275829550824\n",
      "Epoch 157, Loss: 19.499863243698833\n",
      "Epoch 158, Loss: 19.481573002377957\n",
      "Epoch 159, Loss: 19.463403456775534\n",
      "Epoch 160, Loss: 19.445353045532844\n",
      "Epoch 161, Loss: 19.427420273214626\n",
      "Epoch 162, Loss: 19.40960369592828\n",
      "Epoch 163, Loss: 19.39190191170804\n",
      "Epoch 164, Loss: 19.374313554067395\n",
      "Epoch 165, Loss: 19.356837287650844\n",
      "Epoch 166, Loss: 19.33947180527077\n",
      "Epoch 167, Loss: 19.32221582585266\n",
      "Epoch 168, Loss: 19.305068092972146\n",
      "Epoch 169, Loss: 19.28802737377394\n",
      "Epoch 170, Loss: 19.27109245813481\n",
      "Epoch 171, Loss: 19.254262157980534\n",
      "Epoch 172, Loss: 19.237535306698593\n",
      "Epoch 173, Loss: 19.220910758609673\n",
      "Epoch 174, Loss: 19.204387388474654\n",
      "Epoch 175, Loss: 19.18796409102324\n",
      "Epoch 176, Loss: 19.171639780495767\n",
      "Epoch 177, Loss: 19.155413390193836\n",
      "Epoch 178, Loss: 19.139283872037524\n",
      "Epoch 179, Loss: 19.123250196128353\n",
      "Epoch 180, Loss: 19.107311350318096\n",
      "Epoch 181, Loss: 19.091466339783683\n",
      "Epoch 182, Loss: 19.07571418660898\n",
      "Epoch 183, Loss: 19.06005392937402\n",
      "Epoch 184, Loss: 19.044484622752265\n",
      "Epoch 185, Loss: 19.02900533711649\n",
      "Epoch 186, Loss: 19.01361515815374\n",
      "Epoch 187, Loss: 18.998313186489618\n",
      "Epoch 188, Loss: 18.983098537322284\n",
      "Epoch 189, Loss: 18.967970340066156\n",
      "Epoch 190, Loss: 18.95292773800546\n",
      "Epoch 191, Loss: 18.93796988795769\n",
      "Epoch 192, Loss: 18.923095959946814\n",
      "Epoch 193, Loss: 18.90830513688619\n",
      "Epoch 194, Loss: 18.89359661427099\n",
      "Epoch 195, Loss: 18.878969599880094\n",
      "Epoch 196, Loss: 18.86442331348706\n",
      "Epoch 197, Loss: 18.849956986580093\n",
      "Epoch 198, Loss: 18.83556986209077\n",
      "Epoch 199, Loss: 18.821261194131235\n",
      "Epoch 200, Loss: 18.807030247739576\n",
      "Epoch 201, Loss: 18.79287629863329\n",
      "Epoch 202, Loss: 18.778798632970425\n",
      "Epoch 203, Loss: 18.76479654711819\n",
      "Epoch 204, Loss: 18.750869347428868\n",
      "Epoch 205, Loss: 18.737016350022582\n",
      "Epoch 206, Loss: 18.723236880576987\n",
      "Epoch 207, Loss: 18.709530274123278\n",
      "Epoch 208, Loss: 18.695895874848603\n",
      "Epoch 209, Loss: 18.682333035904453\n",
      "Epoch 210, Loss: 18.668841119220893\n",
      "Epoch 211, Loss: 18.655419495326413\n",
      "Epoch 212, Loss: 18.64206754317317\n",
      "Epoch 213, Loss: 18.62878464996743\n",
      "Epoch 214, Loss: 18.615570211005032\n",
      "Epoch 215, Loss: 18.602423629511676\n",
      "Epoch 216, Loss: 18.589344316487868\n",
      "Epoch 217, Loss: 18.57633169055828\n",
      "Epoch 218, Loss: 18.563385177825506\n",
      "Epoch 219, Loss: 18.55050421172788\n",
      "Epoch 220, Loss: 18.537688232901353\n",
      "Epoch 221, Loss: 18.52493668904517\n",
      "Epoch 222, Loss: 18.512249034791257\n",
      "Epoch 223, Loss: 18.499624731577203\n",
      "Epoch 224, Loss: 18.487063247522663\n",
      "Epoch 225, Loss: 18.47456405730904\n",
      "Epoch 226, Loss: 18.462126642062405\n",
      "Epoch 227, Loss: 18.44975048923951\n",
      "Epoch 228, Loss: 18.43743509251666\n",
      "Epoch 229, Loss: 18.425179951681628\n",
      "Epoch 230, Loss: 18.412984572528106\n",
      "Epoch 231, Loss: 18.40084846675301\n",
      "Epoch 232, Loss: 18.388771151856258\n",
      "Epoch 233, Loss: 18.376752151043046\n",
      "Epoch 234, Loss: 18.364790993128526\n",
      "Epoch 235, Loss: 18.352887212444802\n",
      "Epoch 236, Loss: 18.341040348750102\n",
      "Epoch 237, Loss: 18.32924994714024\n",
      "Epoch 238, Loss: 18.317515557961997\n",
      "Epoch 239, Loss: 18.305836736728658\n",
      "Epoch 240, Loss: 18.29421304403744\n",
      "Epoch 241, Loss: 18.282644045488787\n",
      "Epoch 242, Loss: 18.271129311607528\n",
      "Epoch 243, Loss: 18.25966841776585\n",
      "Epoch 244, Loss: 18.24826094410785\n",
      "Epoch 245, Loss: 18.23690647547585\n",
      "Epoch 246, Loss: 18.225604601338308\n",
      "Epoch 247, Loss: 18.21435491571926\n",
      "Epoch 248, Loss: 18.203157017129254\n",
      "Epoch 249, Loss: 18.192010508497837\n",
      "Epoch 250, Loss: 18.180914997107337\n",
      "Epoch 251, Loss: 18.16987009452811\n",
      "Epoch 252, Loss: 18.158875416555098\n",
      "Epoch 253, Loss: 18.147930583145687\n",
      "Epoch 254, Loss: 18.13703521835881\n",
      "Epoch 255, Loss: 18.126188950295315\n",
      "Epoch 256, Loss: 18.11539141103945\n"
     ]
    }
   ],
   "source": [
    "backtracking_theta = backtraking_softmax(X_train, y_train, eta=1, m=0.5, alpha=0.5, batch_size=1024, epochs=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a03d6c-ff9a-4b37-afef-c2133557a6b6",
   "metadata": {},
   "source": [
    "### Dự đoán mô hình với thuật toán quay lui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b65e3fc5-7b91-446c-a427-187cf3700494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Các lớp được dự đoán cho tập huấn luyện với 20 dữ liệu đầu với thuật toán quay lui:\n",
      " [21 11  8  2 21 16  9  3  7 10 14  4  3  2 21 18 24 11 23 19 24 16 12 16\n",
      " 20 21 13 21 17 13]\n",
      "Các lớp thực sự cho tập huấn luyện với 20 dữ liệu đầu với thuật toán quay lui:\n",
      " [21 11  8  2 21 10  9  3  7  6  9  2  3  6 21  0 24 11 23 19 24  6 12 16\n",
      " 20 21 20 24 23 13]\n",
      "Độ chính xác cho tập huấn luyện với thuật toán quay lui: 72.12%\n",
      "Precision có trọng số trên tập huấn luyện với thuật toán quay lui: 0.72\n",
      "Recall có trọng số trên tập huấn luyện với thuật toán quay lui: 0.72\n",
      "F1 score có trọng số trên tập huấn luyện với thuật toán quay lui: 0.72\n"
     ]
    }
   ],
   "source": [
    "# Dự đoán trên tập huấn luyện với thuật toán quay lui\n",
    "Y_train_pred = predict(backtracking_theta, X_train)\n",
    "print(\"Các lớp được dự đoán cho tập huấn luyện với 20 dữ liệu đầu với thuật toán quay lui:\\n\", Y_train_pred[:30])\n",
    "print(\"Các lớp thực sự cho tập huấn luyện với 20 dữ liệu đầu với thuật toán quay lui:\\n\", y_train[:30])\n",
    "\n",
    "acc_train = accuracy_score(y_train.T, Y_train_pred)\n",
    "print(f\"Độ chính xác cho tập huấn luyện với thuật toán quay lui: {acc_train:.2f}%\")\n",
    "\n",
    "# Tính Precision, Recall và F1 score trên tập huấn luyện với thuật toán quay lui\n",
    "precision, recall, f1 = calculate_f1_score(y_train, Y_train_pred)\n",
    "\n",
    "print(f'Precision có trọng số trên tập huấn luyện với thuật toán quay lui: {precision:.2f}')\n",
    "print(f'Recall có trọng số trên tập huấn luyện với thuật toán quay lui: {recall:.2f}')\n",
    "print(f'F1 score có trọng số trên tập huấn luyện với thuật toán quay lui: {f1:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a067bc99-f78a-4d93-b5f7-1a5b2fe27cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Các lớp được dự đoán cho tập kiểm thử với 20 dữ liệu đầu với thuật toán quay lui:\n",
      " [14 17  5  5 19 19  1  5  2 14 21  8  7 17 11  1  5 23  5  4]\n",
      "Các lớp thực sự cho tập kiểm thử với 20 dữ liệu đầu với thuật toán quay lui:\n",
      " [21 11  8  2 21 10  9  3  7  6  9  2  3  6 21  0 24 11 23 19]\n",
      "Độ chính xác cho tập kiểm thử với thuật toán quay lui: 71.92%\n",
      "Precision có trọng số trên tập kiểm thử với thuật toán quay lui: 0.72\n",
      "Recall có trọng số trên tập kiểm thử với thuật toán quay lui: 0.72\n",
      "F1 có trọng số trên tập kiểm thử với thuật toán quay lui: 0.71\n"
     ]
    }
   ],
   "source": [
    "# Dự đoán trên tập kiểm thử với thuật toán quay lui\n",
    "Y_test_pred = predict(backtracking_theta, X_test)\n",
    "print(\"Các lớp được dự đoán cho tập kiểm thử với 20 dữ liệu đầu với thuật toán quay lui:\\n\", Y_test_pred[:20])\n",
    "print(\"Các lớp thực sự cho tập kiểm thử với 20 dữ liệu đầu với thuật toán quay lui:\\n\", y_train[:20])\n",
    "acc_test = accuracy_score(y_test.T, Y_test_pred)\n",
    "print(f\"Độ chính xác cho tập kiểm thử với thuật toán quay lui: {acc_test:.2f}%\")\n",
    "\n",
    "# Tính Precision, Recall và F1 score trên tập kiểm thử với thuật toán quay lui\n",
    "test_precision, test_recall, test_f1 = calculate_f1_score(y_test, Y_test_pred)\n",
    "\n",
    "print(f'Precision có trọng số trên tập kiểm thử với thuật toán quay lui: {test_precision:.2f}')\n",
    "print(f'Recall có trọng số trên tập kiểm thử với thuật toán quay lui: {test_recall:.2f}')\n",
    "print(f'F1 có trọng số trên tập kiểm thử với thuật toán quay lui: {test_f1:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6578f390-7349-44dc-bf54-116a2c3310de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Các lớp được dự đoán cho tập thẩm định với 20 dữ liệu đầu với thuật toán quay lui:\n",
      " [13  5  2 17  9 11  0  1 17 25 18  1 15 11 12 17  5 12  4 19]\n",
      "Các lớp thực sự cho tập thẩm định với 20 dữ liệu đầu với thuật toán quay lui:\n",
      " [13  5  6 17  9 11  0  1 18 25 18  1 15 11 13 17  5 12  4 19]\n",
      "Độ chính xác cho tập thẩm định với thuật toán quay lui: 71.87%\n",
      "Precision có trọng số trên tập thẩm định với thuật toán quay lui: 0.72\n",
      "Recall có trọng số trên tập thẩm định với thuật toán quay lui: 0.72\n",
      "F1 score có trọng số trên tập thẩm định với thuật toán quay lui: 0.71\n"
     ]
    }
   ],
   "source": [
    "# Dự đoán trên tập thẩm định với thuật toán quay lui\n",
    "Y_val_pred = predict(backtracking_theta, X_val)\n",
    "print(\"Các lớp được dự đoán cho tập thẩm định với 20 dữ liệu đầu với thuật toán quay lui:\\n\", Y_val_pred[:20])\n",
    "print(\"Các lớp thực sự cho tập thẩm định với 20 dữ liệu đầu với thuật toán quay lui:\\n\", y_val[:20])\n",
    "\n",
    "acc_val = accuracy_score(y_val.T, Y_val_pred)\n",
    "print(f\"Độ chính xác cho tập thẩm định với thuật toán quay lui: {acc_val:.2f}%\")\n",
    "\n",
    "# Tính Precision, Recall và F1 score trên tập thẩm định với thuật toán quay lui\n",
    "val_precision, val_recall, val_f1 = calculate_f1_score(y_val, Y_val_pred)\n",
    "\n",
    "print(f'Precision có trọng số trên tập thẩm định với thuật toán quay lui: {val_precision:.2f}')\n",
    "print(f'Recall có trọng số trên tập thẩm định với thuật toán quay lui: {val_recall:.2f}')\n",
    "print(f'F1 score có trọng số trên tập thẩm định với thuật toán quay lui: {val_f1:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
